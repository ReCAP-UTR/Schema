Argument-Mining from Podcasts Using ChatGPT
TMG@ICCBR2023
Mircea-Luchian Pojoni, LorikDumani, RalfSchenkel

Methods:
- OpenAI's Whisper to transcript audio to text
- GPT-4 to mine arguments

Input_1: Audio files (expecting podcasts)
Output_1: transcriptions (in txt)

Input_2: txt files (expecting transcriptions)
Output_2: arguments containing "Major claims, premises, counterarguments, rebuttals" or arguments containing "claims, premises, and stances"


###############################################


Trust me, I am an Expert: Predicting the Credibility of  Experts for Statements
TMG@ICCBR2023
Markus Nilles, Lorik Dumani, RalfSchenkel

Method: Cross-Encoder with RoBERTa for three-way classification (no expert, somewhat expert, absolute expert).

Input:
- a person with a Google Scholar profile (with specified research interesets and published papers).
- a sentence 
Output: prediction whether the person is an expert in the field the sentence relates to.


###############################################


QualiAssistant: Extracting Qualia Structures from Texts
ArgMining-Workshop 2022
Manuel Biertz, Lorik Dumani, Markus Nilles, Björn Metzler, Ralf Schenkel

Method: open-source Java system using Part-of-speech to identify the four Qualia roles in all languages as long as constituency trees can be generated and patterns are provided.

Input: plain text

Output: automatic generated annotations showing the found Qualia roles.


###############################################


Fine and Coarse Granular Argument Classification before Clustering
CIKM2021
Lorik Dumani, Tobias Wiesenfeldt, Ralf Schenkel

Method: combined classifications: SVM for stance, Naive Bayes for frame and hierarchical clustering.

Input:
- query
- arguments relevant to that query

Output:
- clustered arguments in different granularities: stance, frame, meaning.


###############################################


Quality-Aware Ranking of Arguments
CIKM2020
Lorik Dumani, Ralf Schenkel

Method: Argument search system using the Args corpus to find similar claims to a query to identify relevant premises and re-rank them by their argument quality dimensions.

Input:
- Query
- Dataset with pro and con arguments (tested with the Args corpus)

Output: A list of pro and con arguments ranked by relevance to the query and by their argument quality dimensions.


### RELATED TO THAT PAPER:

QuARk: A GUI for Quality-Aware Ranking of Arguments
SIGIR2021
Markus Nilles, Lorik Dumani, Ralf Schenkel
-> GUI for normal non-experts looking for arguments

Ranking Arguments by Combining Claim Similarity  and Argument Quality Dimensions
CLEF2020
Lorik Dumani, Ralf Schenkel
-> summary of that paper as notebook due to the participation at Touché

A framework for argument retrieval: Ranking argument clusters by frequency and specificity
Lorik Dumani, Patrick J. Neumann, Ralf Schenkel
-> Precursor of the paper. Here, the output consists of a ranking resulting from frequency of arguments instead of argument quality dimensions.

A systematic comparison of methods for finding good premises for claims
SIGIR2019
Lorik Dumani, Ralf Schenkel
-> Evaluierung über die Ähnlichkeit von Claims zum Finden relevanter Prämissen.


###############################################

Segmenting and Clustering Noisy Arguments
Lorik Dumani, Christin Katharina Kreutz, Manuel Biertz, Alex Witry, Ralf Schenkel

Method:
- a rule-based approach trying to automate the identification of EDUs in the gold dataset.
- BERT, ELMo, and InferSent to cluster these EDUs.

Input (fix): 30 queries, 480 premises

Output: EDUs and their clustering to the query.

###############################################


